\subsection{Derivation of the \TRACELOG Condition}
\label{sxn:TraceLogDerivation}


\subsubsection{Setting up the Saddle Point Approximation (SPA)}
\label{sxn:TraceLogDerivation_A}
As in \EQN~\ref{eqn:IZG_dmuS}, 
we can write \EQN~\ref{eqn:IZG_QT} in terms of the $\AMATN = \SMAT\SMAT^{\top}$ form of the Outer \Student Correlation matrix, giving
\begin{align}
\IZG = \ln\INTS d\mu(\SMAT) \exp\left(\ND\beta N \Trace{ \tfrac{1}{N}\TMAT^{\top}\AMATN \TMAT } \right)
\end{align}
where $d\mu(\SMAT)$ is the measure over all $N \times M$ real-valued random matrices,
although we really want to limit this to all $N \times M$ real matrices that resemble the \Teacher $\TMAT$,
which we clarify below.

To transform $\IZG$ into a form we can evaluate using Tanaka's result~\cite{Tanaka2008}, 
we need to change the measure from an integral over all random $N \times M$ student weight matrices
$d\mu(\SMAT)$ to an integral over all $N \times N$
student correlation matrices $d\mu(\AMATM)$, i.e., $d\mu(\SMAT)\rightarrow d\mu(\AMATM)$.
To accomplish this, we can insert an integral over the Dirac Delta function
\begin{align}
  \label{eqn:I}
  \mathbf{I}:=
% \int d\mu(\AMATM)\delta(N\AMATM-\SMAT^{\top}\SMAT) =
  \int d\mu(\AMATM)\delta(N\AMATM-\SMAT^{\top}\SMAT).
\end{align}

\noindent
(This is simply a resolution of the Identity.) This gives
\begin{align}
\label{eqn:IZG_3}
\IZG= \ln \INTS d\mu(\SMAT)\INTA d\mu(\AMATM)
           \delta\left( N\AMATM-\SMAT^{\top}\SMAT \right) 
           e^{ \ND\beta N Tr[\tfrac{1}{N} \TMAT^{\top} \AMATN\TMAT ] } ,
\end{align}
\red{fix this} where $d\mu(\AMAT)=\Probab{\AMAT}d\AMAT$ and $\Probab{\AMAT}$ is the
(still unspecified) probability density over the new random matrix $\AMAT$. 
%
Let us express \EQN~\ref{eqn:IZG_3} at \LargeN limit in $N$ as
\begin{align}
  \label{eqn:IZG_4}
  \lim_{N\gg 1}\IZG =
  \lim_{N\gg 1}\ln
  \int d\mu(\AMAT)
  \int d\mu(\SMAT)
  \delta(N\AMATM-\SMAT^{\top}\SMAT)
  e^{ \ND\beta N Tr[ \tfrac{1}{N}\TMAT^{\top}\AMATN\TMAT]) }  .
\end{align}
 
Now we assume we can first evaluate the term 
\begin{align}
  \lim_{N\gg 1} \int d\mu(\SMAT)    \delta(N\AMATM-\SMAT^{\top}\SMAT)
\end{align}
at \LargeN in $N$ using a \SaddlePointApproximation (SPA). Using the relation, 
%\begin{align}
%\label{eqn:DeltaA}
%\delta(N\AMAT-\SMAT^{\top}\SMAT)
%   = \dfrac{1}{(2\pi)^{N\red{M}/2}}\INTAHAT  d\mu(\AHAT) e^{ iN Tr[\AHAT\AMAT] } e^{ -i Tr[\AHAT\SMAT^{\top}\SMAT] } 
%\end{align}
\begin{align}
\delta(N\AMATM-\SMAT^{\top}\SMAT)
   =\mathcal{N}_M\INTAHAT  d\mu(\AHAT) e^{ iN Tr[\AHAT\AMATM] } e^{ -i Tr[\AHAT\SMAT^{\top}\SMAT] }  ,
\end{align}
where $\AHAT$ is an $M \times M$ auxiliary matrix, and the domain of integration $d\mu(\AHAT)$ is all $M \times M$ real-valued matrices, and where the normalization $\NORM_1$ is
\begin{align}
  \label{eqn:norm_1}
\NORM_1:=\frac{1}{(2\pi)^{M(M+1)/4}},
\end{align}
because $\AMAT$ is a symmetric matrix with $M(M+1)/2$ constraints.

This is simply the matrix generalization of
$\delta(x)=\dfrac{1}{2\pi}\int_{-\infty}^{\infty} e^{i\hat{x}x}d\hat{x}$,
so we can express the delta function as an exponential, giving
\begin{align}
\label{eqn:Q2}
\IZG = \NORM_1 \ln\INTS  d\mu(\SMAT) \INTA d\mu(\AMATM) 
                           \INTAHAT d\mu(\AHAT) e^{ iN Tr[ \AHAT\AMATM ] }
                           e^{ -i Tr[ \AHAT\SMAT^{\top} \SMAT ] }
                           e^{  \ND\beta N Tr[\tfrac{1}{N} \TMAT^{\top}\AMATN\TMAT ] } .
\end{align}

Rearranging terms, we obtain 
\begin{align}
\label{eqn:IZG_Gamma1}
\IZG =  \ln\INTA  d\mu(\AMATM) 
            e^{  \ND\beta N Tr[\tfrac{1}{N} \TMAT^{\top}\AMATN\TMAT ] } \times
           \Gamma_1,
\end{align}
where we define $\Gamma_1$ as 
\begin{align}
\Gamma_1 := \Gamma_1(\AMATM) 
         = \NORM_1 \INTS d\mu(\SMAT) 
                           \INTAHAT d\mu(\AHAT) e^{ iN Tr[ \AHAT\AMATM ] }
                                                           e^{ -i Tr[ \AHAT\SMAT^{\top} \SMAT ] } .
\end{align}
We can simplify the complex integral in $\Gamma_1$ with the Wick Rotation $i\AHAT\rightarrow\AHAT$.
The Wick rotation ensures that the Gaussian integral converges (although this has not been rigorously checked).
We may expect $d\mu(\AHAT)$ to be invariant to rotations in the complex plane,
so the Wick rotation does not introduce any complex prefactors. This gives
\begin{eqnarray}
\label{eqn:QWick}
\Gamma_1 = \NORM_1 \INTS d\mu(\SMAT)\INTAHAT d\mu(\AHAT) 
           e^{ N  Tr[ \AHAT\AMATM ] }
           e^{ - Tr[ \AHAT\SMAT^{\top} \SMAT] } \\
\label{eqn:QWick2}
         = \NORM_1 \INTS d\mu(\SMAT)\INTAHAT d\mu(\AHAT) 
           e^{ N  Tr[ \AHAT\AMATM ] }
           e^{ -Tr[ \SMAT\AHAT\SMAT^{\top} ] } ,
\end{eqnarray}
where the second line follows since the trace is invariant under cyclic permutations (i.e., $\Trace{ABC}=\Trace{BCA}=\Trace{CAB}$).
Swapping the order of the integrals yields
\begin{eqnarray}
\label{eqn:QWick3}
\Gamma_1 =\Gamma_1(\AHAT)  = \NORM_1
           \INTAHAT d\mu(\AHAT) 
           e^{ N Tr[\AHAT\AMATM ]}\times
           \Gamma_2  ,
\end{eqnarray}
where we define $\Gamma_2$ as
\begin{equation*}
\Gamma_2 := \Gamma_2(\AHAT)
         = \INTS d\mu(\SMAT)
           e^{ -Tr[ \SMAT\AHAT\SMAT^{\top} ] } .
\end{equation*}

To evaluate $\Gamma_2$, we will make several mathematically convenient approximations.
(These will yield an approximate expression which can be verified empirically.)
\michaeladdressed{MM TO DO: point explicitly to the main text where we made these explicit, if/when that is the case.}
%
We first assume for the purpose of changing measure that the (data) columns of $\SMAT$ are
statistically independent, so that the measure $d\mu(\SMAT)$ factors into $N$ Gaussian distributions
\begin{align}
\label{eqn:dMuS}
d\mu(\SMAT) = \prod_{\mu=1}^{N}d\mu(\mathbf{s}_{\mu})=\prod_{\mu=1}^{N}d\mathbf{s}_{\mu} ,
\end{align}
where $\mathbf{s}_{\mu}$ is an M-dimensional vector.
The singular values of $\SMAT$ are invariant to random permutations of the columns or rows,
so the resulting ESD does not change.  
This is very different from permuting $\SMAT$ element-wise, which will make the resulting ESD Marchenko Pastur (MP).

Using \EQN~\ref{eqn:dMuS}, 
$\Gamma_2$ reduces to a simple Gaussian integral, which can be evaluated as a product of $N$ Gaussian integrals (over the $M\times M$ matrix $\AHAT$)
\begin{align}
\label{eqn:int-out-J2}
\Gamma_2
   =& \left[\INTsvec d\mathbf{s}e^{-\tfrac{1}{\sigma^{2}} \mathbf{s}\AHAT\mathbf{s}^{\top} }\right]^{N} \\
   =& \left[\NORM_2\;\Det{\AHAT}^{-1/2}\right]^{N}  ,
\end{align}
where the normalization term $\NORM_2$
\begin{align}
\label{eqn:norm_2}
%\NORM_2 := \left((2\pi)^{N/2}\sigma^{2}\right)^{M}  ,
\NORM_2 := \left(\pi\sigma^{2}\right)^{M/2}  ,
\end{align}
where $\sigma^{2}=\mathbf{s}^{\top}\mathbf{s}=\red{2?}1/M$
\charles{Need to be very careful here.  Is this $1/N$ or $1/M$ ?  See also A2. We pick $\sigma^{2}=1/M$ to ensure the normalization on $\XI$ is correct.
This needs to be double checked.}

For any square, non-singular matrix $\AHAT$,  $ \Trace{\ln\AHAT}=\ln \Det{\AHAT}$, so
it follows from \EQN~\ref{eqn:int-out-J2} that
\begin{align}
\nonumber
\ln\Gamma_2
   &=N\ln\NORM_2\left[( \Det \AHAT)^{-1/2} \right]  \\   %  &=\tfrac{NM}{2}\ln (2\pi)^{N/2}\sigma^{2}-\tfrac{N}{2}\ln det\;\AHAT     
&= N\ln\NORM_2 -\tfrac{N}{2}\Trace{ \ln\AHAT }  ,
\end{align}
so that
\begin{align}
\label{eqn:log-Gamma}
\Gamma_2 = (\NORM_2)^{N} e^{ -\tfrac{N}{2} Tr[ \ln\AHAT ] } 
\end{align}

Substituting
\EQN~\ref{eqn:log-Gamma}
into \EQN~\ref{eqn:QWick3},
we can write $\Gamma_1$ as
\begin{eqnarray}
  \label{eqn:gamma1}
\Gamma_1(\AHAT)  =& C_{\Gamma_1}\INTAHAT d\mu(\AHAT)   e^{ N Tr[ \AHAT\AMATM ] }  e^{ -\tfrac{N}{2} Tr[ \ln\AHAT ] }  ,
\end{eqnarray}
where
\begin{equation}
    C_{\Gamma_1}:=\NORM_1 e^{\NORM_2}.
\end{equation}

We can now evaluate the integral in \EQN~\ref{eqn:QWick3} over the Lagrange multiplier $\AHAT$ (i.e., $\INTAHAT $). 
If we call this $\Gamma_1(\AHAT)$,
then (following Tanaka~\cite{Tanaka2008}) we can define the \emph{\RateFunction} $I(\AHAT,\AMATM)$ such that
\begin{align}
\label{eqn:LambdaA}
\Gamma_1(\AHAT)=\INTAHAT  d\mu(\AHAT) e^{-NI(\AHAT,\AMATM)}  ,
\end{align}
where
\begin{align}
\label{eqn:IAA}
I(\AHAT,\AMATM) = -\Trace{ \AHAT\AMATM} + \frac{1}{2}\Trace{ \ln\AHAT }  .
\end{align}


We can formally evaluate the integral in \EQN~\ref{eqn:LambdaA} in the large-$N$ limit using a \SaddlePointApproximation (SPA)
(see Section~\ref{sxn:mathP}, \EQN~\ref{eqn:SPA}), as
\begin{align}
\label{eqn:LAMBDA}
\Gamma_1(\AHAT)\rightarrow \sqrt{\dfrac{(2\pi)^{N/2}}{N\Vert I\Vert}}e^{-N I^{*}(\AHAT, \AMATM)}  ,
\end{align}
where $I^{*}(\AHAT,\AMAT)$ is the maximum value over all $\AHAT$ for fixed $\AMATM$, obtained using
\begin{align}
  \label{eqn:IAA-sup}
  I^{*}(\AHAT,\AMATM) :=
\underset{N\gg 1}{\lim} I(\AHAT,\AMATM) =
 \underset{\AHAT}{\sup}\left[-\Trace{\AHAT\AMATM}+\frac{1}{2}\Trace{\ln\AHAT}\right]  ,
\end{align}
where at the SPA we have stationarity,
\begin{align}
  \label{eqn:SP0}
  \dfrac{\partial}{\partial\AHAT}I(\AHAT,\AMATM) =& -\AMATM+\dfrac{1}{2\AHAT}=0  
\end{align}
and the Hessian of $I$ becomes
\begin{align}
  \label{eqn:Ixx}
\frac{\partial^2 }{\partial \hat{A}^2} I(\AHAT,\AMATM)= -\frac{1}{2} \left( \frac{1}{2} \hat{A}^{-1} \right) \otimes \left( \frac{1}{2} \hat{A}^{-1} \right) = -\frac{1}{8} \AMATM \otimes \AMATM
\end{align}
where $\otimes$ is the Kronecker product. Using \EQN~\ref{eqn:SP0}, we have that $1 / 8$ $\AMATM \otimes \AMATM$ is the saddle point Hessian of $I$ w.r.t. $\AMATM$. Solving the SPA equation, we find that %the auxiliary matrix is $\AHAT=\tfrac{1}{2}\AMATM^{-1}$ and
the prefactor (i.e. Hessian) is given as
$ \Det{-\frac{1}{8} \AMATM \otimes \AMATM} = \left( -\frac{1}{8} \right)^{M^2} \left(  \Det{\AMATM} \right)^M$.   

Substituting for $\AHAT$ into \RateFunction (\EQN~\ref{eqn:IAA}), $I$ becomes
\begin{align}
\label{eqn:IAA_2}
I^{*}(\AHAT,\AMATM) = -\Trace{ \IM } + \frac{1}{2}\Trace{ \ln\AMATM }   \\ \nonumber
 = -M + \frac{1}{2}\Trace{ \ln\AMATM }  .
\end{align}

\noindent
In order for this result to be physically meaningful, 
we need that if $I^{*}(\AHAT,\AMATM)$ grows,
then it must grow slower than $N$, and,
more importantly, that $\Det{\AMAT}$ be non-zero.
Importantly, when $\Det{\AMAT}=1$ exactly, however, then $\Gamma_1$ becomes a constant,
and this simplifies things considerably!

\subsubsection{Casting the \GeneratingFunction \texorpdfstring{$(\IZG)$}{beta G} as an HCIZ Integral}
\label{sxn:TraceLogDerivation_B}

In this section, we express the \GeneratingFunction $\IZG$, 
given in \EQN~\ref{eqn:IZG_dmuS} (equivalently, in \EQN~\ref{eqn:betaIZG_S},) 
as an HCIZ Integral, 
as given in \EQN~\ref{eqn:IFA2_braket}.
\michael{@charles: make sure I got those numbers correct.  BTW, I think it makes sense to explicitly call out the HCIZ equation by itself in a self-contained statement, so then we can point to it rather than \EQN~\ref{eqn:IFA2_braket}, which uses HCIZ in our context; if so, would you do that.}
\charles{You mean like what you did in Appendix A6, \EQN~\ref{eqn:hciz2} ?  Thats good, and that can go early on, in section 3 or 4}

Inserting $I^{*}(\AHAT,\AMAT)$ from \EQN~\ref{eqn:IAA_2} into $\IZG$, we obtain
\begin{align}
  \label{eqn:IZG_IAA}
  \IZG 
  & =  \ln \left[ C_{\Gamma_1} e^{-NM}\int d\mu(\AMAT)
  e^{\ND\beta N Tr[ \tfrac{1}{N}\TMAT^{\top}\AMATN\TMAT] }
  e^{\tfrac{N}{2}\ln(\Det{\AMATM})}\right]  \\ \nonumber
  & =
    \ln  C_{\Gamma_1}
  - NM
  +  \ln \left[ \int d\mu(\AMAT)
    e^{\ND\beta N Tr[ \tfrac{1}{N}\TMAT^{\top}\AMATN\TMAT] }
    e^{\tfrac{N}{2}\ln(\Det{\AMATM})}\right]  .
\end{align}

\noindent
%Since $C_{\Gamma_1}$ is complex, we must choose a branch to evaluate $\ln\;C_{\Gamma_1} $.
%However, this term is constant and is bounded by $1$, 
%so we simply need to choose the branch such that $\ln\;C_{\Gamma_1}$ vanishes in the large-N limit $\lim_{N\rightarrow\infty}\tfrac{1}{N}\IZG$.
So long as the second term $\Trace{\mathbb{I}_{M}}$ does not depend on $N$, 
it will vanish when we take the partial derivative of $\IZG$ to obtain the $\AVGNNGE$, in which case it is not important.  
We can then simply write the \GeneratingFunction $\IZG$  as in \EQN~\ref{eqn:IFA2_integral} as:
\begin{align}
  \label{eqn:IZG_integral}
  \IZG 
   =  \ln \left[ \int d\mu(\AMATM)
    e^{\ND\beta N Tr[ \tfrac{1}{N}\TMAT^{\top}\AMATN\TMAT] }
    e^{\tfrac{N}{2}\ln(\Det{\AMATM})}\right]  ,
\end{align}
or, in \BraKet notation, as
\begin{align}
  \label{eqn:IZG_braket}
  \IZG = 
   \ln\left\langle
  e^{\ND\beta N Tr[ \tfrac{1}{N}\TMAT^{\top}\AMATN\TMAT] }
  e^{\tfrac{N}{2}\ln(\Det{\AMATM})}
  \right\rangle_{\AMATM}   .
\end{align}


%In order to evaluate this integral, we must deal with the term $ln(\Det{\AMAT_{1}})$.
%To do so, we will restrict both $\AMAT_{1}$ and $\AMAT_{2}$ to a low-rank subspace where
%$\Det{\AMAT}=\Det{\AMAT_{1}}=\Det{\AMAT_{2}}$
%is well defined, finite, and empirically measurable.

%
%
%\paragraph{Restricting $\AMAT$ to the Effective Correlation Space (\ECS).}
%
%As discussed Section~\ref{sxn:matgen}, 
%we expect the \Student \CorrelationMatrix $\AMAT$ to resemble the \Teacher \CorrelationMatrix $\XMAT$;
%and, specifically, we expect both $\AMAT$ and $\XMAT$ to have the same limiting ESD,
%$\rho^{\infty}_{\AMAT}(\lambda)=\rho^{\infty}_{\XMAT}(\lambda)$.
%Likewise, we might expect the $\Det{\AMAT}$ to equal the empirically measured one, i.e.,
%$\mathbb{E}[\Det{\AMAT}]=\Det{\XMAT}$.
%%%and we are done. But 
%In practice, 
%however, 
%%%$\mathbf{\top}$ is \HeavyTailed Power-Law for the best models, and empirically ,
%$\Det{\XMAT}\approx 0$,
%even for very good models that have ESDs that are well-pit to PL or TPL distributions, 
%because there are frequently a large number of very small eigenvalues ($\ln\lambda<1.0$) in the bulk part of the ESD. 
%
%For this result to be physically meaningful, we must restrict the Correlation Matriecs
%($\AMAT$ and $\XMAT$) to an \EffectiveCorrelationSpace (\ECS), 
%i.e., $\AECS$ (and $\XECS$), such that we $\mathbb{E}[\Det{\AECS}]=\Det{\XECS}>0$.
%We can now express $\IZG$ as an HCIZ integral in \EQN~\ref{eqn:IZG_integral} as
%\begin{align}
%  \label{eqn:IZG_integral2}
%  \IZG = \red{\cancel{\frac{1}{N}}}
%  \ln \int d\mu(\AECS)
%  e^{\ND\beta N Tr[ \tfrac{1}{N}\TMAT^{\top}\AECS_{2}\TMAT] }
%  e^{\tfrac{N}{2}\ln(\Det{\AECS})}  ,
%\end{align}
%where have now written $\AECS_{2}$ explicitly for clarity.
%\michael{We are talking about cutting off small eigenvalues, but then we seem to swap $\AECS_{1}$ and $\AECS_{2}$; need to clarify something.}
%\michael{I think it is okay; MM to confirm.}
%We may also write this using \BraKet notation as
%\begin{align}
%  \label{eqn:IZG_braket2}
%  \IZG = 
%  \ln \left\langle
%  e^{\ND\beta N Tr[ \tfrac{1}{N}\TMAT^{\top}\AECS_{2}\TMAT] }
%  e^{\tfrac{N}{2}\ln(\Det{\AECS})}
%  \right\rangle_{\AECS}  .
%\end{align}
%
%
%\paragraph{Independent Fluctuation Approximation (IFA).}
%
%We now introduce a key approximation, the IFA, 
%in which we factor the terms in \EQN~\ref{eqn:IZG_braket2} into two distinct, 
%statistically independent averages over $\AECS$, giving
%\begin{align}
%  \label{eqn:IFA}
%  \IZG \approx
%  \ln\left[
%  \left\langle
%  e^{\ND\beta N Tr[ \tfrac{1}{N}\TMAT^{\top}\AECS_{2}\TMAT] }
%  \right\rangle_{\AECS}
%  \left\langle
%  e^{\tfrac{N}{2}\ln(\Det{\AECS})}
%  \right\rangle_{\AECS} \right]
%\end{align}
%
%\noindent
%Recall that we expect the \Student Correlation matrix to resemble that of the \Teacher.
%By resemble, we mean that both matrices have the same limiting ESD, $\rho^{infty}_{\AECS}=\rho^{infty}_{\XECS}$.
%We also now assume we can estimate the expected value of $\Det{\AECS}$ with the empirical estimate
%from the \Teacher, i.e.,
%\begin{align}
%  \langle \Det{\AECS}\rangle_{\AECS}\approx  \langle \Det{\XECS} \rangle_{\XECS} .
%\end{align}
%
%Fortunately, and rather remarkably, it turns out that when the PL exponent $\alpha=2$, we can
%select $\XECS$ such that $\Det{\XECS}=1$ by simply defining the ECS as the eigen-components spanned by the PL tail.
%Therefore, in this analysis, we will replace $\AMAT$ with $\AECS$, i.e., $\AMAT\rightarrow\AECS$ 
%and set $\Det{\AECS}=1$.
%\michael{MM: Iths par should maybe be moved to the main text.}
%
%\paragraph{The Final Generating Function $\IZG$ for the Quality (Squared) as an HCIZ Integral.}
%With this, we can write $\IZG$ as an HCIZ integral as in \EQN~\ref{eqn:hciz}
%\michael{@charles: what equation should that HCIZ reference be.}
%in \BraKet notation as
%\begin{align}
%  \label{eqn:IZG_final_hciz}
%  \IZG := & \red{\cancel{\frac{1}{N}}}\left\langle     \exp ( \ND\beta N \Trace{\tfrac{1}{N} \TMAT^{\top}\AECS_{2}\TMAT })\right\rangle_{\AECS}  ,
%\end{align}
%or explicitly as an integral as
%\begin{align}
%  \label{eqn:IZG_final_integral}
% \IZG  := & \red{\cancel{\frac{1}{N}}}\int d\mu(\AECS) \exp \left( \ND\beta N \Trace{\tfrac{1}{N} \TMAT^{\top}\AECS_{2}\TMAT }\right)  ,
%  \end{align}
%or in Tanakas notation as
%\begin{align}
%  \label{eqn:IZG_final_tanaka}
% \IZG  := & \red{\cancel{\frac{1}{N}}}\mathbb{E}_{\AECS}\left[ \exp \left( \ND\beta N \Trace{\tfrac{1}{N} \TMAT^{\top}\AECS_{2}\TMAT }\right)\right]  ,
%\end{align}
%where in each case $\AHAT$ is restricted to the \EffectiveCorrelationSpace (\ECS) 
%such that $ln\Det{\AHAT}=0$ and $\AHAT$ is normalized to $M$.
%\nred{CLEAN THIS UP: As discussed in SubSection~\ref{sxn:appendix_Gan}}.
%
%We note that
%$$ \langle\cdots\rangle_{A} = \int \;[\cdots]\; \; d\mu(A) = \mathbb{E}_{A}[\cdots] $$
%are equivalent notations denoting the expected value (or average) over all \Student Correlation Matrices $\AECS$ spanning the ECS,
%$\AECS_{2}$ is a (random) $N\times N$ square (correlation) matrix, and
%$\TMAT$ is a (non-random) \Teacher $N\times M$ rectangular (weight) matrix.
%That is, $\TMAT$ the actual layer weight matrix $\TMAT=\tilde{\mathbf{W}}$ of the model we wish to study
%(but also only in the span of the ECS).
%Notice also that, here,  $\beta$ is the inverse-Temperature and not the simple constant $1$ or $2$ as in \cite{Tanaka}.
%\michael{It seems like this par should be somewhere else. Maybe the math section.}
%


\subsection{Tanaka's Result}
\label{sxn:tanaka}

In this section, we will rederive the result by Tanaka~\cite{Tanaka2007,Tanaka2008} that we use in our main derivation,
and, importantly, explain how to address the missing Temperature term.
For completeness, we restate it here using the notation of the main text:
%Tanaka states the as have the following HCIZ (Harish-Chandra/Itzykson-Zuber) integral~\cite{BP2001}
\begin{equation}
  \label{eqn:hciz}
  \lim_{N \gg 1} \frac{1}{N} \ln 
\underbrace{
  \Expected[\mathbf{\AMAT}]{
    \exp\left(\frac{\beta}{2}
    \Trace{\mathbf{W}^{\top} \AMAT_{2} \mathbf{W}}
    \right)
  }
 }_{\text{HCIZ Integral}}
  = \frac{\beta}{2} \sum_{i=1}^{M} \GNORM(\lambda_{i})
\end{equation}
where 
$\mathbf{W}$ is the $N\times M$ \Teacher weight matrix, 
$\AMAT=\AMAT_{2}$ is the $N\times N$ \Student (correlation) matrix, 
but $\beta$ is now the inverse-Temperature(because we are working with real matrices),
and we have added a $\tfrac{1}{2}$ (which will be clear later).
$\GNORM(\lambda)$ is a complex analytic function of the eigenvalues $\lambda$ of (the \Teacher Correlation matrix) $\XMAT$, 
whose functional form will depends on the structure of limiting form of (the \Student) ESD $\rho_{\AMAT}^{\infty}(\lambda)$.
We call it the \emph{\red{Norm?} \GeneratingFunction};
\michael{I think calling $\GNORM(\lambda)$ a Norm \GeneratingFunction will be confusing, unless the thing it generates is precisely a norm, which I think it is not.}
\michael{Also, I think the mathbb is confusing on the $G$ here, but especially on the $Z$ below, since it makes it look like integers, real numbers, etc., and not a function.
}
\charles{Its hard to find different but similar notation for new things.  Suggestions ?}
and we may also write it as $\GNORM(\XMAT)$ below.
\michael{
We refer to Tanaka in at least three sets of different letters: 
$\mathbf{W}$ in \ref{eqn:hciz}; 
$\AMAT$ and $\BMAT$ around \ref{eqn:izgin_def,eqn:hciz_tanaka}; and
$\TMAT$ in \ref{eqn:tanaka_result}.
But this equation here is also referred to as HCIZ, and we refer to HCIZ with different sets of letters.
I am in the process of cleaning this up.
}

To apply this result, we note that
while the term $\beta$ is just a constant in~\cite{Tanaka2008}
($1$ or $2$, depending on whether the random matrix is real or complex),
it is not actually inverse Temperature $\beta=\tfrac{1}{T}$ in the original derivation.
Still, we seek a final result that is linear in $\beta=\tfrac{1}{T}$,
so that we can easily evaluate $\QT$ in the high-T limit, i.e.
$\QT
=\tfrac{\partial}{\partial N}\tfrac{1}{\beta}\IZGINF
=\tfrac{\partial}{\partial \beta}\tfrac{1}{N}\IZGINF$
(see \ref{eqn:IZG_QT}).
We can introduce $\beta=\tfrac{1}{T}$ by
simply changing the scale of $\AMAT_{2}$ since the final result is a sum of \RTransforms, which by definition
are linear, i.e. $\GNORM(\beta\lambda)=\beta \GNORM(\lambda)$, however, it is instructive
rederive the final result, with $\beta$ explicitly included.
\michaeladdressed{@charles: what is the point of this comment?  Is it just that if temperature is constant, then the derivative is simple, since we dont need the chain rule.  Also, this comment is about applying this result; do we need it for the derivation?}

%%Also, notice there is an extra $\tfrac{1}{2}$ term in the exponential; this term will factor out later, but it is added here to make it easier to see how to apply the \emph{Large Deviation Principle} (LDP); this not essential but is nice to have
%%\nred{I may remove this}
%%\michael{I would say include the 1/2, for expositional clarity; it helped me.}


\paragraph{Notation.}

We start by re-writing the Tanaka result, \EQN~(\ref{eqn:hciz}),
in our notation for the expected value $\Expected[\AMAT]{\cdots}$ operator, as follows:
\begin{equation}
\label{eqn:hciz2}
  \tfrac{1}{2}\IZGINF = \lim_{N\gg 1} \ln \underbrace{ \int d\mu(\mathbf{\AMAT})\left[\exp\left(\frac{\beta}{2}\Trace{\mathbf{W}^{\top}\AMAT_{2}\mathbf{W}}\right)\right] }_{\mbox{HCIZ Integral}} 
  = N\beta\tfrac{1}{2}\sum_{i=1}^{M}\GNORM(\lambda_{i})   .
\end{equation}
where we have added a $\tfrac{1}{2}$ for technical convenience (to make the connection with the LDP, below).
\michaeladdressed{What are we trying to rewrite? Since this equation is not just \EQN~(\ref{eqn:hciz}) with a different notation for the expectation: it has a new LHS and it doesnt have the RHS of \EQN~(\ref{eqn:hciz}).}
If we denote the internal HCIZ integral as 
%%MM%% $\HCIZ$,  which
%%MM%% denoting the \PartitionFunction for our matrix generalization of the ST model.
%%MM%% This gives
\begin{equation}
\label{eqn:hciz_def}
  \HCIZ := \int d\mu(\mathbf{\AMAT})\left[\exp\left(\frac{\beta}{2}\Trace{\mathbf{W}^{\top}\AMAT_{2}\mathbf{W}}\right)\right]  ,
 \end{equation}
then it holds that %% Thus, %%MM%% such that
\begin{equation}
  \label{eqn:hciz_def2}
  \IZG :=  \ln\HCIZ  ,
\end{equation}
from which it follows that %%MM%% or, equivalently,
\begin{equation}
\label{eqn:hciz_def3}
  \IZGINF := \lim_{N \gg 1} \ln\HCIZ  .
\end{equation}
%%%CHM%%%\charles{Should this be $\beta\mathbf{\bar{\Gamma}}^{IZ}_{N\gg 1}$,
%%%CHM%%%  specifically with the bar to indicate that this is an average.
%%%CHM%%%  That is, did we get the $1/N$ term right here and in A4?
%%%CHM%%%  And if so, when we defined the generalization error above in Eqn~\ref{eqn:avgge_def},
%%%CHM%%%  did we use $F$ or $\bar{F}$. Or does this depend on how we defined $\HANHT$ ?
%%%CHM%%%  Getting this $1/N$ right is critical because we need to take something like
%%%CHM%%%  \begin{align}
%%%CHM%%%    \QT =\dfrac{1}{\beta} \dfrac{\partial}{\partial N}\IZGINF =
%%%CHM%%%    \dfrac{1}{N} \dfrac{\partial}{\partial \beta}\IZGINF  
%%%CHM%%%  \end{align}
%%%CHM%%%  But now I'm not entirely sure if this is the Average \LayerQuality
%%%CHM%%%  or the Total \LayerQuality
%%%CHM%%%  Moreover, what what we expect is (from Paris Bouchaud, etc)
%%%CHM%%%  \begin{align}
%%%CHM%%%    \HCIZ \rightarrow_{N \gg 1} \exp\left[N\beta\sum \GNORM\right]
%%%CHM%%%  \end{align}
%%%CHM%%%  which gives
%%%CHM%%%  \begin{align}
%%%CHM%%%    \IZGINF = \ln\HCIZ_{N \gg 1} = N\beta\sum \GNORM
%%%CHM%%%  \end{align}
%%%CHM%%%}
\michaeladdressed{Having the mathbb on this $Z$ seems pretty confusing, since it looks like a set of integers. What are the drawbacks of just using $Z$, or some other related letter?}
%%
%%\michael{Those two expressions are consistent with what is going on in the main text, but from the persepctive of this self-contained appendix, they are basically definitions to simplify the derivation of \EQN~(\ref{eqn:hciz}), correct?  }
%%
The SPA approximates the \PartitionFunction $\HCIZ$, which is now an HCIZ integral,  by its peak value.
For this, $\GNORM(\lambda)$ itself must either not explicitly depend on $N$ and/or at least not grow faster than $N$.
%\nred{For that reason, I think we need to normalize the eigenvalue as $\lambda/N$, or rather $\lambda/M$, or maybe $\lambda/\MECS$, as with the normalization constrain on $\XECS$.}

The trick here is we can choose an \RTransform of $\mathbf{\AMAT}$
that is a simple analytic expression based on the observed
the empirical spectral density (ESD) of the $\mathbf{X}$.
And this can readily be done for the ESDs for a wide range of layer weight matrices
observed in modern DNNs because the their ESDs are \HeavyTailed \PowerLaw\cite{MM19_HTSR_ICML}.
We can then readily express the \Quality $\Q$ of the \Teacher
layer in a simple functional form, (i.e  an approximate Shatten Norm),

Importantly, the matrices $\mathbf{X}$  and $\mathbf{\AMAT}$ must be well approximated
by low rank matrices since the derivation in Tanaka requires this.  Fortunately,
this appears to be generally true for the layers in very well trained DNNs,
which is what allows us to apply this withing the~\ECS.

Finally, we note that $\GNORM(\mathbf{X})$ is kind of \emph{Generalized Norm} because 
it can be evaluated as a sum over a function of the $M$ eigenvalues $\lambda_{\mu}$ of the \Teacher
correlation matrix $\mathbf{X}=\frac{1}{N}\mathbf{W}^{\top}\mathbf{W}$.
$\GNORM(\mathbf{X})$  will turn out to be a simple expression similar to the Frobenius Norm or the
Shatten Norm of $\mathbf{X}$, depending on the functional form we choose to model the
lmiting form of the \Student ESD, $\rho_{\AMAT}^{\infty}(\lambda)$.

\michael{Those three paragraphs are more like comments, so shouldnt be here in the appendix. Put at the right spot in the main text.}
\charles{@michael: where ? }
\nred{BELOW: The normalization factors below may be off since these are symmetric matrices.
  For example, for the $M\times M$ $\AMAT$, there are $M(M+1)/2$, not $M^2$, degrees of freedom.
  These minor errors are not material to the derivations below but they needs to be fixed before publication.
  }
\input{appendix/A61_tanaka}
\input{appendix/A62_tanaka}
\input{appendix/A63_tanaka}
\input{appendix/A64_tanaka}
\input{appendix/A65_tanaka}

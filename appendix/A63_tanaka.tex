\subsubsection{Step 2: The Saddle Point Approximation (SPA): Explicitly forming the Large Deviation Principle (LDP)}
\label{sxn:tanaka_step2}
We now evaluate $\EZDA$ in \EQN~\ref{eqn:ZD1} as $\EZDATWO$ 
to  establish \EQN~\ref{eqn:ZD_step2}, \charles{in Steps $2.1-2.6$}.

Using the LDP (and following similar approaches in spin glass theory \cite{PP95}),
below we will show that we can write the expected value of $\ZD$ 
in terms of $d\mu(\mathbf{X})$ now (which is equivalent to $d\mu(\AMATM)$)
and in the large-$N$ approximation, as
\begin{equation}
  \label{eqn:LDP}
 \lim_{N \gg 1} \EZDAONE=
  \int\exp\left(\ND\beta N \Trace{\GNORM(\mathbf{X})}-NI(\mathbf{X})+o(N)\right)d\mu(\mathbf{X})
\end{equation}
where $I(\mathbf{X})$ is \RateFunction, defined below,
and $\GNORM(\mathbf{X})$ is what we are eventually solving for.

\paragraph{Step 2.0} We start with the \emph{expected} \PartitionFunction
\begin{align}
  \label{eqn:avg_ZD}
  \EZDATWO
  &=
  \int d\mu(\AMAT)\int  d\mu(\WMAT)
      \exp\Bigl[
         \tfrac{\ND\beta}{2}\Trace{\WMAT^{\TR}\AMATN\,\WMAT}
        -\tfrac{\ND\beta}{2}\Trace{\WMAT\DMAT\WMAT^{\TR}}
      \Bigr].
\end{align}
The average over $\AMATN$ affects only the first exponential; applying the SPA, we
\textbf{define} a matrix function $\GFANCY$, depending solely on
$\XMAT=\frac1N\WMAT^{\TR}\WMAT$, by
\begin{align}
  \label{eqn:def_GFANCY}
  \int d\mu(\AMAT)\,
        \exp\Bigl[\tfrac{\ND\beta}{2}\Trace{\WMAT^{\TR}\AMATN\,\WMAT}\Bigr]
  &=
  \exp\Bigl[\tfrac{\ND\beta N}{2}\Trace{\GFANCY}\Bigr].
\end{align}
which will be valid in the large-$N$ approximation below.

We now note that given the duality of measures, we can assert 
\begin{equation}
\EZDA=\EZDAONE=\EZDATWO.
\end{equation}
This lets us insert \eqref{eqn:def_GFANCY} into \eqref{eqn:avg_ZD} and then write
\begin{align}
  \label{eqn:ZD_after_Aavg}
  \EZDA
  &=
  \int d\mu(\WMAT)
      \exp\Bigl[
         \tfrac{\ND\beta N}{2}\Trace{\GFANCY}
        -\tfrac{\ND\beta}{2}\Trace{\WMAT\DMAT\WMAT^{\TR}}
      \Bigr].
\end{align}

The now need to determine an explicit form for
$\GFANCY$. We introduce a new change of measure, 
 $d\mu(\mathbf{W})\rightarrow d\mu(\mathbf{X})$.
Then, we show this lets us express $\EZDA$ as $\EZDX$ and to express it using the LDP.
Next, we apply a SPA to solve for $\GMAX=max\;\GNORM$.
Importantly, we also show how to incorporate the inverse-Temperature $\ND\beta$,
which is new.

\paragraph{Step 2.1}
To define the transformation $d\mu(\mathbf{W})\rightarrow d\mu(\mathbf{X})$,  where (recall) $\mathbf{X}=\frac{1}{N}\mathbf{W}^{\top}\mathbf{W}$,
we use the (again) the integral representation of the Dirac delta-function $\delta(x)$:
\begin{equation}
  \label{eqn:dirac}
  \delta(x):=\frac{1}{2\pi}\int_{-\infty}^{\infty} e^{i\hat{x}x} d\hat{x}.
\end{equation}
%
This lets us express the transformation of measure $d\mu(\mathbf{W})\rightarrow d\mu(\mathbf{X})$
(approximately) as
\begin{align}
\nonumber
  d\mu(\mathbf{W}) &:= \delta(\frac{1}{2}\Trace{N\mathbf{X}-\mathbf{W}^{\top}\mathbf{W}}) d\mu(\mathbf{X}) \\ 
  &= \frac{1}{2\pi}\int_{-\infty}^{\infty} e^{i\frac{1}{2}
    \Trace{\hat{X}(N\mathbf{X}-\mathbf{W}^{\top}\mathbf{W})}
  }
  d\mu(\mathbf{X})d\mu(\hat{X} ),
\end{align}
where $\hat{X}$ is a scalar (or really a matrix of scalars),
and we have a $1/2$ term for mathematical consistency below.
\footnote{The full change of measure would require a delta function constraint
for each matrix element $X_{i,j}$, i.e., 
$\delta\left(\frac{1}{2}N\left(X_{i,j}-[\mathbf{W}^{\top}\mathbf{W}]_{i,j}\right)\right)$.
Here, we assume the Trace constraint is sufficient for our level of rigor.
}



\paragraph{Step 2.2}
Next, we take a Wick Rotation%
\footnote{The Wick rotation converts an oscillatory integral into an exponentially decaying one which should be well defined.  Technically, this is an analytic continuation which needs to be checked, but following standard practice in physics we will assume the resulting integral is analytic and therefore well defined and we will proceed onward. },
$i\XHAT\rightarrow -\XHAT$, so that the terms under the integral are all real (not complex), giving:
\begin{align}
  \label{eqn:dmuX}
  d\mu(\mathbf{W}) &= \mathcal{N}_{Wick}\int_{-i\infty}^{i\infty} e^{\frac{1}{2}\Trace{\hat{X}(N\mathbf{X}-\mathbf{W}^{\top}\mathbf{W})}} d\mu(\mathbf{X})d\mu(\hat{X} ).
\end{align}
where $d\mu(\hat{X})$ is a measure over $\tfrac{M(M-1)}{2}$ Lagrange multipliers, and the normalization is $\mathcal{N}_{Wick}=(\frac{1}{2\pi i})^{\tfrac{M(M-1)}{2}}$.

\paragraph{Step 2.3}
We now insert \ref{eqn:dmuX} into~\ref{eqn:ZD_after_Aavg}, which lets us
express $\EZDA$ as an integral over the \Teacher Correlation matrices.

\begin{align}
  \nonumber
  \EZDA&=
  \mathcal{N}_{Wick} \int_{\XMAT}  \int_{-i\infty}^{i\infty}
  e^{N\frac{\ND\beta}{2} \Trace{\GFANCY}+\frac{N}{2}\Trace{\hat{X}\mathbf{X}} }
  e^{-\frac{1}{2}\Trace{\hat{X}\mathbf{W}^{\top}\mathbf{W}}}
  e^{\frac{\ND\beta}{2}\Trace{\mathbf{W}\mathbf{D}\mathbf{W}^{\top}}}
  d\mu(\hat{X} )
  d\mu(\mathbf{\XMAT}) \\ 
  \nonumber
  &=
  \mathcal{N}_{Wick} \int_{\XMAT}  \int_{-i\infty}^{i\infty}
  e^{N\frac{\ND\beta}{2}\Trace{\GFANCY}+ \frac{N}{2}\Trace{\hat{X}\mathbf{X}}}
  e^{-\frac{1}{2}\Trace{\mathbf{W}\hat{X}\mathbf{W}^{\top}}+
  \frac{\ND\beta}{2}\Trace{\mathbf{W}\mathbf{D}\mathbf{W}^{\top}}}
  d\mu(\hat{X} )
  d\mu(\mathbf{\XMAT}) \\ 
  \label{eqn:ZD3}
    &=
  \mathcal{N}_{Wick} \int_{\XMAT}  \int_{-i\infty}^{i\infty}
  e^{N\frac{\ND\beta}{2}\Trace{\GFANCY}+
  \frac{N}{2}\Trace{\hat{X}\mathbf{X}}}
  e^{\frac{1}{2}\Trace{\mathbf{W}(\ND\beta\mathbf{D}-\hat{X})\mathbf{W}^{\top}}}
  d\mu(\hat{X} )
  d\mu(\mathbf{\XMAT})  .
\end{align}

\paragraph{Step 2.4}
We can now rearrange terms to make this expression look like the \EQN~\ref{eqn:LDP}
%Let us write
%express \EQN~\ref{eqn:ZD3} as the expected value $\EZDA$ in terms of 
%\michael{Huh?}
%\charles{SOME EXPLANATIONS NEEDED: }
%\begin{equation}
%  \EZDA=\int\exp\left(\ND\beta N\Trace{\GNORM}-NI(\mathbf{X})+o(N)\right)d\mu(\mathbf{X})
%\end{equation}


In Large Deviations Theory, the \RateFunction is defined by the Legendre Transform,
\begin{equation}
\label{eqn:rate-fun}
    \mathcal{I}(\mathbf{X})=\underset{\mathbf{\check{X}}}{\sup}
    \left[Tr\dfrac{1}{2}\mathbf{{X}}^{\top}\mathbf{\check{X}}-\ln\mathbb{M}(\mathbf{\check{X}})\right]  ,
\end{equation}
where $\mathbb{M}(\mathbf{\check{X}})$ is the \MomentGeneratingFunction,
$\ln\mathbb{M}(\mathbf{\check{X}})$, is the \CumulantGeneratingFunction, and
and $\mathbf{\check{X}}$ is a (matrix of) \emph{Lagrange Multiplier}(s).  $\mathbb{M}(\mathbf{\check{X}})$ is defined in terms of the (unnormalized) density $p(\mathbf{x})$ as
\begin{equation}
\label{eqn:rate_function}
   \mathbb{M}(\mathbf{\check{X}})=\exp\left(\frac{1}{2}\mathbf{x}^{\top}\mathbf{\check{X}}\mathbf{x}\right)  ,
  p(\mathbf{x})d\mathbf{x}
\end{equation}
which, in turn, is defined in terms of the source matrix $\mathbf{D}$,
\begin{equation}
\label{eqn:X_density}
p(\mathbf{x})=\exp\left(-\tfrac{1}{2}\mathbf{x}^{\top}\ND\beta\mathbf{D}\mathbf{x}\right)  .
\end{equation}
%
The moment generating function $ \mathbb{M}(\mathbf{\check{X}})$ is then given by
%
\begin{equation}
\mathbb{M}(\mathbf{\check{X}}) 
   = \int \exp\left(-\frac{1}{2}\mathbf{x}^T(\ND\beta\mathbf{D} - \mathbf{\check{X}})\mathbf{x}\right) d\mathbf{x} 
   = (2\pi)^{\frac{M}{2}} \Det{\ND\beta\mathbf{D} - \mathbf{\check{X}}}^{-\frac{1}{2}}  .
\end{equation}

\paragraph{Step 2.5}
The \SaddlePointApproximation (SPA) can be used to solve for $\mathcal{I}(\mathbf{\check{X}})$ 
by solving for the stationary conditions
\begin{equation}
  \frac{\partial}{\partial \mathbf{\check{X}}} I(\mathbf{X},\mathbf{\check{X}}) = 0  .
\end{equation}
%
First, let us compute $ \ln \mathbb{M}(\mathbf{\check{X}}) $ as:
%
\begin{equation}
\ln \mathbb{M}(\mathbf{\check{X}}) = \frac{M}{2} \ln(2\pi) - \frac{1}{2} \ln \Det{\ND\beta\mathbf{D} - \mathbf{\check{X}}}.
\end{equation}
\michael{Make det notation consistent throughout.}
\charles{OK lets double check that everywhere;}
%
Substituting this into the expression for the Legendre transform, we obtain:
%
\begin{equation}
I(\mathbf{X},\mathbf{\check{X}}) 
   = \sup_{\mathbf{\check{X}}} \left[\frac{1}{2} \Trace{\mathbf{X} \mathbf{\check{X}}} - \frac{M}{2} \ln(2\pi) + \frac{1}{2} \ln \Det{\ND\beta\mathbf{D} - \mathbf{\check{X}}} \right].
\end{equation}
%
The supremum of this expression is attained at the value of $\mathbf{\check{X}}$ that satisfies:
%
\begin{equation}
\frac{\partial}{\partial \mathbf{\check{X}}} \left[\frac{1}{2} \Trace{\mathbf{X} \mathbf{\check{X}}} + \frac{1}{2} \ln \Det{\ND\beta\mathbf{D} - \mathbf{\check{X}}} \right] = 0.
\end{equation}
%
Taking the derivative, we obtain
%
\begin{equation}
\frac{1}{2} \mathbf{X} + \frac{1}{2} (\ND\beta\mathbf{D} - \mathbf{\check{X}})^{-1} = 0,
\end{equation}
%
which simplifies to:
%
\begin{equation}
\mathbf{X} = (\ND\beta\mathbf{D} - \mathbf{\check{X}})^{-1} \quad \Rightarrow \quad \mathbf{\check{X}} = \ND\beta\mathbf{D} - \mathbf{X}^{-1}.
\end{equation}
%
Substituting $ \mathbf{\check{X}} = \ND\beta\mathbf{D} - \mathbf{X}^{-1} $ back into the expression for $ I(\mathbf{X})$, we obtain:
%
\begin{equation}
I(\mathbf{X}) = \frac{1}{2} \left[\Trace{\mathbf{X} (\ND\beta\mathbf{D} - \mathbf{X}^{-1})} - \frac{M}{2} \ln(2\pi) + \frac{1}{2} \ln \Det{\mathbf{X}^{-1}}\right].
\end{equation}
%
%
\begin{equation}
\Trace{\mathbf{X}\ND\beta\mathbf{D} - \mathbf{I}} = \Trace{\mathbf{X}\ND\beta\mathbf{D}} - N,
\end{equation}
\begin{equation}
\ln \Det{\mathbf{X}^{-1}} = -\ln \Det{\mathbf{X}},
\end{equation}
we get:
%
\begin{equation}
I(\mathbf{X}) = \frac{1}{2} \left[\Trace{\mathbf{X}\ND\beta\mathbf{D}} - \ln \Det{\mathbf{X}} - M - M\ln(2\pi)\right].
\end{equation}

Finally, we express $I(\mathbf{X})$ in the form:

\begin{equation}
I(\mathbf{X}) = \frac{1}{2} \left[ -M(1 + \ln(2\pi)) + \Trace{\mathbf{X}\ND\beta\mathbf{D}} - \ln \Det{\mathbf{X}} \right].
\end{equation}

\paragraph{Step 2.6}
\begin{equation}
  \ND\beta\GFANCY=\mathbb{M}(1+\ln 2\pi)+\ND\beta\Trace{\GNORM(\mathbf{X})} - \Trace{\mathbf{X}\ND\beta\mathbf{D}} +  \ln \Det{\mathbf{X}}.
\end{equation}

We restrict our solution to those where $\XMAT$ and $\ND\beta\mathbf{D}$ can be diagonalized simultaneously.
In particular, this lets us write
\begin{equation}
\Trace{\mathbf{X}\ND\beta\mathbf{D}} = \sum_{\mu=1}^{M}\ND\beta\delta_{\mu}\lambda_{\mu}   ,
\end{equation}
where $\ND\beta\delta_{\mu}$ and $\lambda_{\mu}$ denote the eigenvalues of $\XMAT$ and $\ND\beta\mathbf{D}$, resp.

We can now write the maximum value of $\GNORM$, $\GMAX$, as
\begin{equation}
\label{eqn:gmax_final}
\ND\beta\GMAX = M \left( 1 + \ln \frac{2\pi}{\ND\beta} \right) - \sum_{\mu=1}^{M} \min_{\ND\beta\delta_{\mu}} \left[\ND\beta\delta_{\mu}\lambda_{\mu}
- \ND\beta\GNORM(\lambda_{\mu}) + \ln \lambda_{\mu} \right]   .
\end{equation}

\section{A \SemiEmpirical Theory of (Deep) Learning (\SETOL)}
\label{sxn:setol}
Based on prior empirical results, and the success of the \ALPHA and \ALPHAHAT metrics that are based on the \HTSR \Phenomenology, this leads to the deeper question: 
%
\begin{quote}
\emph{Why do the \ALPHA and \ALPHAHAT metrics work so well as NN model quality metrics for SOTA NN~models?}
\end{quote}
That is, why do NN models with heavier-tailed layer ESDs tend to generalize better when compared to related models?
Relatedly, can we derive these metrics from first principles?
(If so, then under what conditions do they hold, and under what conditions do they fail?)


\noindent
To answer these questions, we will derive a general expression for the \LayerQuality, $\Q$, of a NN.
Although many modern NNs have many layers, we adopt a single-layer viewpoint (like a matrix-generalized Studentâ€“Teacher) because in \SMOG theory the multi-layer generalization can be factorized or approximated.
For this, we will obtain by simple averaging our model quality metrics, under effectively a single layer approximation, that correspond to \ALPHA and \ALPHAHAT.


In deriving these quantities, we will introduce to NN theory a new \SemiEmpirical approach that combines techniques from \STATMECH and \RMT in a novel way.
The \LayerQuality $\Q$ will estimate the contribution that an individual NN layer makes to the overall quality of a trained NN model.
In deriving $\Q$, we have discovered a new \LayerQuality metric, called the \TRACELOG condition,
which indicates the generalizing components of the layer concentrate into a low-rank subspace
(the \emph{\EffectiveCorrelationSpace}, or~\ECS).
\michaeladdressed{Something about~\ECS here, since we describe it suboptimally above.}
%
(Importantly, we have conducted detailed experiments to show that the key assumptions of our \SETOL theory are valid
(see Sections~\ref{sxn:empirical-effective_corr_space} and \ref{sxn:empirical-trace_log}),
and that the empirical estimates of the \SETOL \TRACELOG condition align remarkably well with predictions from the \HTSR
theory under \Ideal conditions (see Sections~\ref{sxn:empirical-test_acc}).
We also examine how the \HTSR predictions (i.e., the HT PL exponent $\alpha$) behave under non-\Ideal conditions (see Sections~\ref{sxn:empirical-correlation_trap} and \ref{sxn:hysteresis_effect}).)
\michael{Does that outline belong here.}
%
In the following, we will outline key conceptual aspects of \SETOL.
In Section~\ref{sxn:setol_overview}, \michael{we do such-and-such};
In Section~\ref{sxn:ideal_learning}, \michael{we do such-and-such}; and
In Section~\ref{sxn:HT_ESDs}.

%Importantly, it also uses key ideas from \SemiEmpirical quantum chemistry
%\cite{martin_reparametrizing_1998,Martin1996HighlyAA,martin1996redesigning}.


\input{sections/310_setol_overview}
\input{sections/320_setol_comparisons}
\input{sections/330_setol_detecting}

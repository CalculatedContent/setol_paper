%\subsection{Basic Elements of the \SemiEmpirical Theory}
%\label{sxn:matgen_basic_elements_concise}

\begin{enumerate}[label=5.\arabic*]
\item
\textbf{Matrix Generalization of the ST Model.}
Section~\ref{sxn:matgen_mlp3} generalizes
classical \STATMECH vector-based ST model of Section~\ref{sxn:SMOG_main-student_teacher}
to obtain a \LayerQuality for a single layer in a NN.
It starts by first formulating the learning problem for
the NN generalization accuracy or quality, $\Q^{NN}$,
of a 3-layer MLP (MLP3).
We then replace vectors with $N \times M$ matrices $\SVEC,\TVEC\rightarrow\SMAT,\TMAT$,
and obtain and expression for the NN \SelfOverlap $\ETA(\SMAT,\TMAT,\NDXI)$,which then gives a matrix-generalized overlap operator
$\OVERLAP:=\langle\ETA(\SMAT,\TMAT,\NDXI)\rangle_{\AVGNDXI}=\tfrac{1}{N}\SMAT^{\top}\TMAT$.
This can be related to a single-layer matrix-generalization of the ST \AnnealedHamiltonian, 
presented in Appendix~\ref{sxn:summary_sst92},
$\HANHT(\OVERLAP):=N(M-\OVERLAP$),
where, importantly, the scalar overlap $R$ is now a matrix $\OVERLAP$ of $M\times M$ adjustable parameters.
Importantly, being empirical quantities, the weight matrices are implicitly normalized by $1/\ND$, and, like the ST vectors, also implicitly normalized by $1/M$. (See Appendix~\ref{sxn:appendix_Gan}).

\item
\textbf{The \LayerQualitySquared $\QT$.}
Section~\ref{sxn:matgen_quality_hciz} presents the expression for NN \LayerQualitySquared $\QT$.
Following the ST analogy, we define a \ThermalAverage over possible \Student weight matrices $\SMAT$
for the matrix overlap, giving $\Q^{NN}_{L}:=\THRMAVGIZ{\HANHT} =\THRMAVGIZ{\OVERLAP}$.
For technical reasons, however, we actually seek the (approximate)  \LayerQualitySquared, $\QT\approx (\Q^{NN}_{L})^2$,
defined as $\QT:=\THRMAVGIZ{\OLAPTOLAP}$.
To evaluate $\QT$, rather than sampling all random \Student matrices $\SMAT$ directly,
we switch measures to the (Outer) \Student Correlation matrices\footnote{
We adopt the convention ``Inner'' for smaller, $M\times M$ full rank \Student correlation matrices, and ``Outer'' for larger, $N\times N$ rank-deficient \Student Correlation matrices.
Note that both are scaled as $1 / N$, meaning that their nonzero eigenvalues are the same.
} 
$\AMATN = \tfrac{1}{N}\SMAT\SMAT^{\top}$ along with their Inner counterparts
$\AMATM = \tfrac{1}{N}\SMAT^{\top}\SMAT$.
Importantly, we argue that the measures $d\mu(\AMATM)\leftrightarrow d\mu(\AMATN)$,
can be interchanged for our purposes, making them effectively equivalent.
This reparameterization leads us to an integral of the HCIZ type (as in \EQN~\ref{eqn:hciz_prelim})
which, as shown by Tanaka \cite{Tanaka2007, Tanaka2008}, is expressed in terms of the \Rtransform $R_{\AMATM}(z)$, defined for the tail of the limiting form of the ESD of $\AMATM$,  $\rho^{\infty}_{\AMATM}(\lambda$).

Then, we introduce the \EffectiveCorrelationSpace (\ECS), and two key approximations,
the \IndependentFluctuationApproximation (\IFA) and
the Exact Renormalization Group (\TRACELOG) Condition.
We impose the \IFA (described below) because it is necessary for the final result.
The \TRACELOG condition states that the determinant of the (effective) \Student correlation matrix is unity, $\Det{\AECS}=1$.
Critically, this condition can be tested empirically by assuming the (effective) \Teacher correlation matrix
also follows the testable \TRACELOG condition, $\Det{\XECS}=1$. \textbf{The empirically testable \ERG condition is a key result of this work}.


\item
\textbf{The \WideLayer \LargeN limit in $N$.}
Section~\ref{sxn:matgen_evaluation_hciz} presents the core result,
(as in \EQN~\ref{eqn:QT_result}),
closed-form or semi-analytic expression(s) for the \LayerQualitySquared $\QT$
formed in the \WideLayer \LargeN limit in $N$.
Restricted to the \ECS, and under the \TRACELOG condition and the \IFA, our
HCIZ integral for $\QT$ becomes tractable at large-$N$, giving an expression that can be parameterized
in terms of $\MECS$ eigenvalues $\LambdaECS$ of the \Teacher correlation matrix 
restricted to the \ECS $\XECS$.
In doing this, the $\MECS$ \Teacher eigenvalues are treated as experimental observables, and 
become the effective \SemiEmpirical parameters (i.e., $\alpha$, $\LambdaMax$) of the \SETOL approach.

\item
\textbf{Selecting the \HeavyTailed \RTransform.}
Section~\ref{sxn:r_transforms} presents several models of different \RTransforms.
Evaluating $\QT$ requires evaluating selecting an \RTransform $R(z)$ for the Teacher Empirical Spectral Density (ESD),
and also ensure that it is analytic and single-valued on the domain of interest-- the \ECS and/or tail of the ESD.
We examine four possible models for $R(z)$: \emph{(i)} the \emph{Bulk$+$Spikes} (BS),
\emph{(ii)} the \emph{Free Cauchy} (FC) model, 
\emph{(iii)} the \emph{\InverseMP} (IMP) model, 
and \emph{(iv)} the  \LevyWigner (LW) model.
First, as a trivial case, the tail of ESD can be treated as a collection of spikes,
and the ESD is simply a sum of Dirac delta functions; in this case,
$\QT$ becomes a ``Tail Norm'', the Frobenius Norm of the PL tail.
When the layer is \Ideal, i.e., $\alpha\sim 2$ and $\Det{\XECS}\sim 1$,
one can use  \emph{Free Cauchy} (FC) model.  and the resulting \LayerQuality $\Q$
is approximately the Spectral Norm $\LambdaMax$.
Since $\LambdaMax$ increases with decreasing $\alpha$, the FC model yields the \HTSR \ALPHA metric.
One can also use  \emph{\InverseMP} (IMP) model. 
Being a model for the full \Teacher ESD (not just the tail) the IMP \RTransform contains a \emph{branch cut} in the complex plane
which aligns with the start of the \ECS \PowerLaw tail.
Finally, Using the \LevyWigner (LW) model, one can model cases where
$\alpha\le 2$ and derive the \HTSR \ALPHAHAT metric.
\end{enumerate}

\vspace*{1em}

These core elements form a bridge between well-established empirical properties of large-scale NNs 
and a tractable ST-based theory. In the subsequent sections, we formalize the key steps: 
\emph{(i)} setting up the matrix-based ST problem, \emph{(ii)} defining our HCIZ integrals 
over restricted correlation matrices (\ECS), and \emph{(iii)} analyzing the resulting 
\emph{Layer Quality} (or \emph{Quality-Squared}) expressions in the \LargeN limit in $N$.

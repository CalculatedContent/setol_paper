%\subsection{Evaluating the HCIZ Integral in the Large-$N$ Limit}
\subsection{Evaluating the Layer Quality $(\Q)$ in the Large-$N$ Limit}
\label{sxn:matgen_evaluation_hciz}

%%%Here, we model the matrix-generalized Average ST \Quality (Squared)
%%%$\QT$ of an HCIZ integral, and in the large-$N$ limit. 
%%%\michael{Why change notation below?  I sort of like it but sort of dont.}
%%%We can write the generating function $\IZG$ (for the Total Average \Quality Squared $\mathcal{Q}^{2}$)
%%%in \BraKet notation as
%%%\begin{align}
%%%  \label{eqn:IZG_hciz}
%%%  \IZG := & \frac{1}{N}\left\langle     \exp ( N\beta \Trace{\tfrac{1}{N} \TMAT^{T}\AECS_{2}\TMAT })\right\rangle_{\AECS} 
%%%\end{align}
%%%or explicitly as an integral as
%%%\begin{align}
%%%  \label{eqn:IZG_integral}
%%% \IZG  := & \frac{1}{N}\int d\mu(\AECS) \exp ( N\beta \Trace{\tfrac{1}{N} \TMAT^{T}\AECS_{2}\TMAT })
%%%  \end{align}
%%%or, in Tanakas notation,
%%%\begin{align}
%%%  \label{eqn:IZG_tanaka}
%%% \IZG  := & \frac{1}{N}\mathbb{E}_{\AECS}\left[ \exp ( N\beta \Trace{\tfrac{1}{N} \TMAT^{T}\AECS_{2}\TMAT })\right]
%%%\end{align}
%%%where 
%%%$\langle\cdots\rangle_{A}=\int\cdots d\mu(A)=\mathbb{E}_{A}[\cdots]$
%%%are equivalent notation denoting the expected value (or average) over all \Student Correlation Matrices $\AECS$ spaning the~\ECS,
%%%$\AECS_{2}$ is a (random) $N\times N$ square (correlation) matrix, and
%%%$\TMAT$ is a (non-random) \Teacher $N\times M$ rectangular (weight) matrix.
%%%That is, $\TMAT$ the actual layer weight matrix $\TMAT=\tilde{\mathbf{W}}$ of the model we wish to study
%%%(but also only in the span of the~\ECS).
%%%Notice also that, here,  $\beta$ is the inverse-Temperature and not the simple constant $1$ or $2$ as in \cite{Tanaka}.
%%%
%%%\nred{REPEATED AGAIN}
To generate the Average \Quality, $\QT$, we first  take the large-$N$ limit of $\IZG$
\begin{equation}
  \label{eqn:IZG_limit}
  %  \IZGINF := \lim_{N\gg 1}\IZG = \lim_{N\gg 1}\ln\; \mathbb{E}_{\AECS}\left[\exp N\beta\left( \tfrac{1}{N}\Trace{ \TMAT^{\top}\AECS_{2}\TMAT } \right)\right] ,
\IZGINF := \lim_{N \gg 1} \IZG 
= \lim_{N \gg 1} \ln \; 
  \Expected[\AECS]{ 
    \exp\,
      N \beta \Trace{\tfrac{1}{N}\TMAT^{\top}\,\AECS_{2}\,\TMAT}
  } 
\end{equation}
and then take the appropriate partial derivative ,
analogously to as we did for $\AVGSTGE$; see Section~\ref{sxn:quality} for more details.
This gives (as in \EQN~\ref{eqn:QT_def})
\begin{align}
\label{eqn:IZG_generate_Q2}
\QT &:= \frac{1}{\beta}\frac{\partial }{\partial N}\IZGINF  \\ 
&\underset{\text{high-}T}{\approx}
\frac{1}{N}\frac{\partial }{\partial \beta}\IZGINF 
\end{align}
Notice that since we are at high-Temperature, it doesn't matter which partial derivative we take,
and we expect both results to be yield the same expression.

This HCIZ integral in \EQN~\ref{eqn:IZG_limit} can be evaluated
(i.e in the large-$N$ limit) using a result by Tanaka ---provided
the matrix $\AECS_{2}$ is low rank, which holds when the \TRACELOG condition is satisfied.
Thus, moving forward, we will assume an
\EffectiveCorrelationSpace (\ECS) of rank $\MECS$, where $\LambdaECSmin$ is the $M^{th}$-largest eigenvalue of $\XECS$,
and defines the start of the~\ECS (and whatever branchcut is necssary to integrate $R(z)$).

Tanaka's result for the~\ECS can be expressed as:
\begin{equation}
  \label{eqn:tanaka_result}
  \underset{N\gg 1}{\lim}\frac{1}{N}\ln
\Expected[\AECS]{\exp\left(\beta \Trace{\TMAT^{\top}\AECS_{2}\TMAT}\right)}
  =\beta\sum\limits_{i=1}^{\MECS}\;\GNECSI,
\end{equation}
where the sum now only includes the eigenvalues of $\XECS$ (in the~\ECS), $\beta=\tfrac{1}{T}$
is the Inverse-Temperature, and $\LambdaECS$ is an eigenvalue of $\XECS$, the Teacher
Correlation matrix projected into the \ECS space.
$\AECS_{2}$ is the $N \times N$ form of the \Student Correlation matrix,
with $N-M$ non-zero eigenvalues, and $\TMAT$ is the $N\times M$ \Teacher  weight matrix
(also effectively projected into the \ECS, i.e. $\TMAT=\TECS$ here).
$\GNI$ is the \GEN, defined below.
\footnote{We use the notation $\Expected[\AECS]{\cdots}$ for expected value and placed $\tfrac{1}{N}$ on the L.H.S.
to help the reader compare this to the original expressions in~\cite{Tanaka2007, Tanaka2008}.
Also,  in \cite{Tanaka2007, Tanaka2008},$\beta=1|2$, but, in fact, if one inserts $-\beta$ as an inverse-Temperature into the final expression, it simply factors out.}
This gives
\begin{equation}
\label{eqn:tanaka_result2}
\IZGINF = N\beta\sum\limits_{i=1}^{\MECS}\;\GNECSI,
\end{equation}
\michaeladdressed{State this in a self contained way, with rank assumptins, etc.}


This gives a final expression for the Average \LayerQuality (Squared) $\QT$ as
\begin{equation}
\label{eqn:Q2_result}
\QT = \sum\limits_{i=1}^{\MECS}\;\GNECSI,
\end{equation}
Note that $\QT$ is independent of $N$ and $\beta$,
and, indeed, \EQN~\ref{eqn:IZG_generate_Q2} is an equality.

The average \Quality (squared) can be expressed as a sum over
\GeneratingFunctions $\GN$, which depend only the statistical properties of the
actual \Teacher Correlation  matrix  $\XECS$ (projected into the~\ECS).
Each term in the sum, $\GNECSI$, takes the form
\begin{equation}
\label{eqn:generating_function_A}
 \GN:=\int\limits_{0}^{\lambda}R_{\AMAT}(z)dz \xrightarrow{\text{\ECS}}\int\limits_{\LambdaECSmin}^{\lambda}R_{\AECS}(z)dz
\end{equation}
where $R_{\AECS}(\LambdaECS)$ is the \RTransform from RMT,
and $\LambdaECSmin$ is the lower bound of the~\ECS spectrum.
Importantly, the \RTransform for a Heavy-Tailed ESD may have a branchcut at or near the
start of the~\ECS (as explained in Section~\ref{sxn:r_transforms}), so restricting the integrand
to start at $\LambdaECSmin$ is critical.

\charles{
  should we call $\GN$ a Generating Functiton or maybe a Norm \GeneratingFunction because the simplest result is something like a  Trace Norm ?
 }

\charles{removed section below for space reasons; see tex file}
%The \RTransform is like an inverse Greens function and is also a Cumulant generating function.
%\michael{Still to fix this par.}
%Specifically, the $R$-transform arises in RMT in the following way. 
%gWe can define the Greens function $\mathcal{G}_{A}(z)$ for any square, positive-definite matrix $\AECS$ as the Steiljes Transform of the ESD $\rho_{A}(\lambda)$.
%\michael{Clarify.}
%Following Zee~\cite{Zee:Blue}, we call $\mathcal{B}(z)$ the \BlueFunction, which is the functional inverse of $g(\AECS)$
%For example, if $\mathcal{G}_{A}(z)=XXX$ then  $\mathcal{B}(z)=YYY $.
%We can then define the $R$-Transform $R(z)$ in terms of $\mathcal{B}(z)$ as XXX.  
%\michael{What does that mean?}
%\charles{RMT has its own Cumulant generating function}

%\michael{Either modularize thias a remark, or lets give an explicit equation that we need to call for our subsequent derivation, or for others to follow up on our derivation.}
%The $R$-tramsform is commonly referred to as the Cumulant Generating Fucntion for RMT.
%However, it also has another interpretation, which is relevant here. 
%Obviously, the R-tramsform of a matrix $\AECS$ can be thought of as a modified functional inverse of the Greens function for $\AECS$,
%
%More importantly, however, if one considers the $R$-transform of the sum of two matrics $\AECS_{2}+\AECS_{2}$, then the resulting expression represents a kind of single-particle Greens function for the interacting matrices~\cite{Zee:Blue}.
%
%Most importantly, we know the $R$-transform for an HT random matrix with a PL ESD (see \EQN~\ref{eqn:R_PL}, below).

\michael{@charles: if I understand things, the following (until the end of the section) is a big shift; we are going from doing Tanaka, to justifying why we use the empirical data; we should highlight it more clearly.}
\charles{@michael: thats true}

Since we expect the best Students matrices to resemble the actual \Teacher matrices, we expect the \Student correlation matrix $\AECS$ to have similar spectral properties to our actual empirical correlation matrices $\XECS$.
That is, from the perspective of \HTSR theory and the classification into \PhasesOfTraining~\cite{MM18_TR_JMLRversion}, we expect all the $\AECS$ to be in the same phase as $\XECS$ (and, in addition, to have the same PL exponent value).   That is, 
\\
\\
\emph{We expect the \RTransform of $\AECS$ to have the same functional form as the $R$-transform of $\XECS$.}
\\
\\
If our (\Teacher) NN weight matrix exhibits a HT PL, then the tail the ESD ($\rho_{tail}(\lambda)$) of the \Student and \Teacher will both take the limiting form of a PL, with the same empirical variance $\sigma^{2}$ and (critically) the same PL exponent $\alpha$:
\begin{equation}
\label{eqn:R_PL}
  \rho_{tail}[\AECS](\lambda)\sim\rho_{tail}[\XECS](\lambda)\sim\lambda^{-\alpha}.
\end{equation}

Up until this point, our derivation of $\QT$ only depends on the \TRACELOG condition, irrespective of the exact functional form of $R(z)$,
therefore the \SETOL approach tested by examining how well the \TRACELOG condition holds for the layers in very well performing models.
We do this in Section~\ref{sxn:empirical-trace_log}.






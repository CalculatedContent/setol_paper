%\subsection{Evaluating the HCIZ Integral in the Large-$N$ Limit}
\subsection{Evaluating the Layer Quality \texorpdfstring{$(\Q)$}{Q} in the Large-\texorpdfstring{$N$}{N} Limit}
\label{sxn:matgen_evaluation_hciz}

%
To generate the Average \Quality, $\QT$, we first take the \LargeN limit of $\IZG$ in $N$,
\begin{equation}
  \label{eqn:IZG_limit}
\IZGINF := \lim_{N \gg 1} \IZG 
= \lim_{N \gg 1}  \tfrac{1}{N}
\ln \; 
  \Expected[\AECS]{ 
    \exp\,
      N \beta \Trace{\tfrac{1}{N}\TMAT^{\top}\,\AECSN\,\TMAT}
  } 
\end{equation}
and then take the appropriate partial derivative,
analogously to how we did for $\AVGSTGE$; see Section~\ref{sxn:quality} for more details.
This gives (as in \EQN~\ref{eqn:QT_def})
\begin{align}
\label{eqn:IZG_generate_Q2}
\QT &:= \frac{1}{\beta}\frac{\partial }{\partial \ND}\IZGINF  \\ 
&\underset{\text{high-}T}{\approx}
\frac{1}{\ND}\frac{\partial }{\partial \beta}\IZGINF 
\end{align}
Notice that since we are at high-Temperature, it doesn't matter which partial derivative we take,
and we expect both results to be yield the same expression.

This HCIZ integral in \EQN~\ref{eqn:IZG_limit} can be evaluated
(i.e in the \LargeN limit in $N$) using a result by Tanaka ---provided
the matrix $\AECSN$ is low rank, which holds when the \TRACELOG condition is satisfied.
Thus, moving forward, we will assume an
\EffectiveCorrelationSpace (\ECS) of rank $\MECS$, where $\LambdaECSmin$ is the $M^{th}$-largest eigenvalue of $\XECS$,
and defines the start of the~\ECS (and whatever branch-cut is necessary to integrate $R(z)$).

Tanaka's result for the~\ECS can be expressed as:
\begin{equation}
  \label{eqn:tanaka_result}
  \underset{N\gg 1}{\lim}\frac{1}{N}\ln
\Expected[\AECS]{\exp\left(\ND\beta \Trace{\TMAT^{\top}\AECSN\TMAT}\right)}
  =\ND\beta\sum\limits_{i=1}^{\MECS}\;\GNECSI,
\end{equation}
where the sum now only includes the eigenvalues of $\XECS$ (in the~\ECS), $\beta=\tfrac{1}{T}$
is the Inverse-Temperature, $\ND$ is the size of the training dataset, and $\LambdaECS$ is an eigenvalue of $\XECS$, the Teacher
Correlation matrix projected into the \ECS space.
$\AECSN$ is the $N \times N$ form of the \Student Correlation matrix,
with $N-M$ non-zero eigenvalues, and $\TMAT$ is the $N\times M$ \Teacher  weight matrix
(also effectively projected into the \ECS, i.e. $\TMAT\rightarrow\TECS$ here).
$\GNI$ is the \GEN, defined below.
\footnote{We use the notation $\Expected[\AECS]{\cdots}$ for expected value and placed $\tfrac{1}{N}$ on the L.H.S.
to help the reader compare this to the original expressions in~\cite{Tanaka2007, Tanaka2008}.
Also,  in \cite{Tanaka2007, Tanaka2008},$\beta=1|2$, but, in fact, if one inserts $-\beta$ as an inverse temperature into the final expression, it simply factors out.}
This gives
\begin{equation}
\label{eqn:tanaka_result2}
\IZGINF = \ND\beta\sum\limits_{i=1}^{\MECS}\;\GNECSI,
\end{equation}

This gives a final expression for the Average \LayerQuality (Squared) $\QT$ as
\begin{equation}
\label{eqn:Q2_result}
\QT = \sum\limits_{i=1}^{\MECS}\;\GNECSI,
\end{equation}
Note that $\QT$ is independent of $N$ and $\beta$,
and, indeed, \EQN~\ref{eqn:IZG_generate_Q2} is an equality.

The average \Quality (squared) can be expressed as a sum over
\GeneratingFunctions $\GN$, which depend only the statistical properties of the
actual \Teacher Correlation  matrix  $\XECS$ (projected into the~\ECS).
Each term in the sum, $\GNECSI$, takes the form
\begin{equation}
\label{eqn:generating_function_A}
 \GN:=\int\limits_{0}^{\lambda}R_{\AMAT}(z)dz \xrightarrow{\text{\ECS}}\int\limits_{\LambdaECSmin}^{\lambda}R_{\AECS}(z)dz
\end{equation}
where $R_{\AECS}(\LambdaECS)$ is the \RTransform from RMT,
and $\LambdaECSmin$ is the lower bound of the~\ECS spectrum.
Importantly, the \RTransform for a Heavy-Tailed ESD may have a branchcut at or near the
start of the~\ECS (as explained in Section~\ref{sxn:r_transforms}), so restricting the integrand
to start at $\LambdaECSmin$ is critical.

\charles{removed section below for space reasons; see tex file}
%The \RTransform is like an inverse Greens function and is also a Cumulant generating function.
%Specifically, the $R$-transform arises in RMT in the following way. 
%gWe can define the Greens function $\mathcal{G}_{A}(z)$ for any square, positive-definite matrix $\AECS$ as the Steiljes Transform of the ESD $\rho_{A}(\lambda)$.
%Following Zee~\cite{Zee:Blue}, we call $\mathcal{B}(z)$ the \BlueFunction, which is the functional inverse of $g(\AECS)$
%For example, if $\mathcal{G}_{A}(z)=XXX$ then  $\mathcal{B}(z)=YYY $.
%We can then define the $R$-Transform $R(z)$ in terms of $\mathcal{B}(z)$ as XXX.  

%The $R$-tramsform is commonly referred to as the Cumulant Generating Fucntion for RMT.
%However, it also has another interpretation, which is relevant here. 
%Obviously, the R-tramsform of a matrix $\AECS$ can be thought of as a modified functional inverse of the Greens function for $\AECS$,
%
%More importantly, however, if one considers the $R$-transform of the sum of two matrics $\AECS_{2}+\AECS_{2}$, then the resulting expression represents a kind of single-particle Greens function for the interacting matrices~\cite{Zee:Blue}.
%
%Most importantly, we know the $R$-transform for an HT random matrix with a PL ESD (see \EQN~\ref{eqn:R_PL}, below).

Since we expect the best Student matrices to resemble the actual \Teacher matrices, we expect the \Student correlation matrix $\AECS$ to have similar spectral properties to our actual empirical correlation matrices $\XECS$.
That is, from the perspective of \HTSR theory and the classification into \PhasesOfTraining~\cite{MM18_TR_JMLRversion}, we expect all the $\AECS$ to be in the same phase as $\XECS$ (and, in addition, to have the same PL exponent value).   That is, 
\\
\\
\emph{We expect the \RTransform of $\AECS$ to have the same functional form as the $R$-transform of $\XECS$.}
\\
\\
If our (\Teacher) NN weight matrix exhibits a HT PL, then the tail the ESD ($\rho_{tail}(\lambda)$) of the \Student and \Teacher will both take the limiting form of a PL, with the same empirical variance $\sigma^{2}$ and (critically) the same PL exponent $\alpha$:
\begin{equation}
\label{eqn:R_PL}
  \rho_{tail}[\AECS](\lambda)\sim\rho_{tail}[\XECS](\lambda)\sim\lambda^{-\alpha}.
\end{equation}

Up until this point, our derivation of $\QT$ only depends on the \TRACELOG condition, irrespective of the exact functional form of $R(z)$,
therefore the \SETOL approach is tested by examining how well the \TRACELOG condition and the \ECS holds for the layers in very well-performing models.
We do this in Section~\ref{sxn:empirical-trace_log}.






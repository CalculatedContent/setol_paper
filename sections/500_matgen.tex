\section{\SemiEmpirical Theory of the \HTSR Phenomenology}
\label{sxn:matgen}

In this section, we present the main technical elements of our \SemiEmpirical Theory of Deep Learning (\SETOL).
Our goal is to explain and, where possible, derive the \HTSR PL metrics \ALPHA $(\alpha)$ and \ALPHAHAT $\hat{\alpha}$
from first principles, and, in doing so, also present the \TRACELOG condition and
newly proposed \WW\DETX metric.
To do this, we introduce a Matrix Generalization of the Student-Teacher model for a Linear \Perceptron
(See Section~\ref{sxn:SMOG_main-st_av}), 
adapted here for a (3-layer) \MultiLayerPerceptron  (MLP3).
We seek a theory for the \LayerQuality $\Q=\Q^{NN}_{L}$ of a NN, where
this \LayerQuality now corresponds to the (approximate) contribution each layer makes to the total
generalization accuracy, or total \Quality $\Q^{NN}$.
For technical reasons, we actually seek a formal expression(s) for the \LayerQualitySquared,
$\QT\approx(\Q^{NN}_{L})^2$. 
We say that the \SETOL is \SemiEmpirical because the final result $\QT$ is expressed directly in terms
of the empirically observable spectral properties of the Teacher layer weight matrix $\TMAT=\WMAT$.

\input{sections/510_matgen_semiemp_elements}
\input{sections/520_matgen_multilayer_setup}
\input{sections/530_matgen_quality_metrics}
\input{sections/540_matgen_hciz}
\input{sections/550_matgen_r_transforms}
\input{sections/560_matgen_computatonal_rmt}
